{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "153412e6",
   "metadata": {},
   "source": [
    "# MTMount accelerometers \n",
    "MTMount accelerometers readings vs MTMount azimuth and elevation velocities from encoders. \n",
    "\n",
    "First, we will write some code for the MTMount accelerometers. After that, we will get the readings from the VMS accelerometers in HDF5 format from ssh vms-data.cp.lsst.org, and work on the code more. \n",
    "\n",
    "Things to do:\n",
    "- Add top elevation axis accelerations vs AZ and EL\n",
    "- Query for PSD. \n",
    "- FFTs and corr matrix. \n",
    "- Think about rolling average and FFT frate. \n",
    "- More plots. \n",
    "- Add VMS data that Prakruth converted and transfer function with the TMA accelerometers. \n",
    "- Get more ideas on what to do. \n",
    "- Convert X, Y and Z accelerations to AZ and EL accelerations using function below AccelerometerAccels() and plot again\n",
    "- Add in plots where mirror was raised, forces applied etc. \n",
    "- Remove bokeh plots as they are too large and heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0a71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, time, os, asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time, TimeDelta\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "%matplotlib widget\n",
    "import aioinflux\n",
    "import getpass\n",
    "\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import LinearAxis, Range1d, Span, Label\n",
    "# from bokeh.layouts import columns\n",
    "output_notebook()\n",
    "\n",
    "from lsst_efd_client import EfdClient, resample, merge_packed_time_series, rendezvous_dataframes\n",
    "from lsst.ts.idl.enums import MTM1M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2b09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get EFD client\n",
    "\n",
    "summit_client = True\n",
    "\n",
    "if summit_client:\n",
    "    client = EfdClient('summit_efd')\n",
    "else:\n",
    "    client = EfdClient(\"usdf_efd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422db66b-5530-4771-ad37-66a930172fe2",
   "metadata": {},
   "source": [
    "# Declare timestamps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c90662-31f2-4da1-8647-01c6fa8e5a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Times to look at the data\n",
    "# NOTE this timestamp was changed to match up with the HDF5 file -- Prakruth\n",
    "# start = Time(\"2023-05-15T13:20:45\", scale='utc')\n",
    "# end = Time(\"2023-05-15T13:45:02\", scale='utc')\n",
    "\n",
    "# Original timestamp below:\n",
    "start = Time(\"2023-05-30T21:13:50\", scale='utc')\n",
    "end = Time(\"2023-05-30T21:15:50\", scale='utc')\n",
    "\n",
    "## or \n",
    "# window = TimeDelta(300, format = 'sec')\n",
    "# end = start + window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe9d0d-ca7e-4443-8df0-e4cf7da56096",
   "metadata": {},
   "source": [
    "##  Functions for calculating the accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0f3bb-3c56-4264-87e0-1f3d66dc6d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseFields = ['accelerationX', 'accelerationY', 'accelerationZ']\n",
    "sensorNames = ['SST top end ring +x -y', 'SST top end ring -x -y', 'SST spider spindle', 'SST M2 surrogate'] \n",
    "colours = ['red', 'orange', 'blue', 'green']\n",
    "\n",
    "def Locations(sensorName):\n",
    "    # This carries the sensor location information\n",
    "    if sensorName == 'SST top end ring +x -y':\n",
    "        X = 3.876; Y = -3.696; Z = 4.65\n",
    "    if sensorName == 'SST top end ring -x -y':\n",
    "        X = -3.786; Y = -3.786; Z = 4.653\n",
    "    if sensorName == 'SST spider spindle':\n",
    "        X = -1.275; Y = 0.602; Z = 5.383\n",
    "    if sensorName == 'SST M2 surrogate':\n",
    "        X = -1.882; Y = 0.0; Z = 4.342\n",
    "    r_theta = np.sqrt(Z**2 + Y**2)\n",
    "    r_phi = np.sqrt(Z**2 + Y**2 + X**2)\n",
    "    return [X, Y, Z, r_theta, r_phi]\n",
    "    \n",
    "\n",
    "def AccelerometerAccels(packed_dataframe, el, sensorName, start_slew, inPos):\n",
    "    # This rotates the accelerometer accelerations into AzEl space\n",
    "    g = 9.5\n",
    "    rolling_average = 100 # Smooths the noisy data   \n",
    "    sub_df = packed_dataframe.loc[packed_dataframe.sensorName==sensorName] \n",
    "    sub_df = sub_df[(sub_df['timestamp'] > (start_slew - 2.0)) & (sub_df['timestamp'] < (inPos + 1.0))]\n",
    "    el = el[(el['timestamp'] > (start_slew - 2.0)) & (el['timestamp'] < (inPos + 1.0))]\n",
    "    elevations = np.array(el.actualPosition[np.argmin(np.abs(np.subtract(np.array(el.timestamp), \\\n",
    "                                np.expand_dims(np.array(sub_df.timestamp), 0).T)), axis = 1)])\n",
    "    unpacked_elevations = np.repeat(elevations, 200) * np.pi/180.0 # In radians\n",
    "    [X, Y, Z, r_theta, r_phi] = Locations(sensorName) # Get the sensor coordinates\n",
    "    r_phi_axis = np.sqrt((Z * np.cos(unpacked_elevations) \\\n",
    "                          - Y * np.sin(unpacked_elevations))**2 \\\n",
    "                          + X**2)\n",
    "    for baseField in baseFields:\n",
    "        df = merge_packed_time_series(sub_df, baseField, stride=1,\n",
    "                             ref_timestamp_col=\"timestamp\", fmt='unix_tai',\n",
    "                             scale='tai')\n",
    "        if baseField == 'accelerationX':\n",
    "            az_el_accel_df = pd.DataFrame(data = {'AccelerationElevation': np.zeros(len(df.index)), \\\n",
    "                                                  'AccelerationAzimuth': np.zeros(len(df.index)), \\\n",
    "                                                  'times': df['times'] - df['times'].values[0]})\n",
    "            az_el_accel_df['AccelerationAzimuth'] -= (np.array(df['accelerationX']) * (Z * np.cos(unpacked_elevations) \\\n",
    "                                                  - Y * np.sin(unpacked_elevations)) / (r_phi_axis**2)) * 180.0/np.pi\n",
    "        if baseField == 'accelerationY':\n",
    "            df['accelerationY'] -=  g * np.cos(unpacked_elevations)\n",
    "            az_el_accel_df['AccelerationElevation'] += (np.array(df['accelerationY']) * Z / (r_theta**2)) * 180.0/np.pi\n",
    "            az_el_accel_df['AccelerationAzimuth'] -= (np.array(df['accelerationY'])) * np.sin(unpacked_elevations) \\\n",
    "                                                        * (X / (r_phi_axis**2)) * 180.0/np.pi\n",
    "        if baseField == 'accelerationZ':\n",
    "            df['accelerationZ'] -=  g * np.sin(unpacked_elevations)\n",
    "            az_el_accel_df['AccelerationElevation'] -= (np.array(df['accelerationZ']) * Y / (r_theta**2)) * 180.0/np.pi \n",
    "            az_el_accel_df['AccelerationAzimuth'] += (np.array(df['accelerationZ']) * np.cos(unpacked_elevations) \\\n",
    "                                                           * X / (r_phi_axis**2)) * 180.0/np.pi\n",
    "\n",
    "    # Now subtract off the mean.  This shouldn't be necessary if we have successfully removed g\n",
    "    az_el_accel_df['AccelerationAzimuth'] -= az_el_accel_df['AccelerationAzimuth'].mean()\n",
    "    az_el_accel_df['AccelerationElevation'] -= az_el_accel_df['AccelerationElevation'].mean()\n",
    "    # Now do a rolling average to smooth the data\n",
    "    az_el_accel_df['AccelerationAzimuth'] = az_el_accel_df['AccelerationAzimuth'].rolling(rolling_average, center=True).sum() / rolling_average \n",
    "    az_el_accel_df['AccelerationElevation'] = az_el_accel_df['AccelerationElevation'].rolling(rolling_average, center=True).sum() / rolling_average\n",
    "    return az_el_accel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd5866-f9c8-46f3-b34e-24dab59736d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_in_pos(dfPos):\n",
    "    for slew in range(len(dfPos)):\n",
    "        inPosition = Time(dfPos.index[slew], scale='utc')\n",
    "        inPosition_vline = Span(location=inPosition.datetime64, dimension='height', line_color='olivedrab', line_width=0.9, line_dash='dashed')\n",
    "        inPosition_label = Label(x=inPosition.datetime64, text = \"Axis In Position\")\n",
    "        p.add_layout(inPosition_vline)\n",
    "        p.add_layout(inPosition_label)\n",
    "        \n",
    "def show_track_command(dfTrack):\n",
    "    for slew in range(len(dfTrack)):\n",
    "        trackCommand = Time(dfTrack.index[slew], scale='utc')\n",
    "        trackCommand_vline = Span(location=trackCommand.datetime64, dimension='height', line_color='magenta', line_width=0.5, line_dash='dashed')\n",
    "        trackCommand_label = Label(x=trackCommand.datetime64, text = \"CommandAxis\")\n",
    "        p.add_layout(trackCommand_vline)\n",
    "        p.add_layout(trackCommand_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7b94d-b19b-4eec-95a7-ff777bda4e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "\n",
    "def build_df_with_all_accelerometers(packed_df):\n",
    "    for i, sensorName in enumerate(sensorNames):\n",
    "        sub_dataframe = packed_dataframe.loc[packed_dataframe.sensorName==sensorName]\n",
    "        for baseField in baseFields:\n",
    "            df_basefield = merge_packed_time_series(sub_dataframe, baseField, stride=1,\n",
    "                             ref_timestamp_col=\"timestamp\", fmt='unix_tai',\n",
    "                             scale='tai')\n",
    "            # dataframe[f'{baseField}_sensor{i}_times'] = df_basefield['times']\n",
    "            dataframe[f'{baseField[-1]}_sensor{i}'] = df_basefield.iloc[:,0]\n",
    "            \n",
    "    return dataframe      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9335c693-dae0-4c1c-900e-61730f6c8572",
   "metadata": {},
   "source": [
    "##  Query EFD to get MTMount data for the selected times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca9b2-9c6b-4d11-b1a2-04f3dc57927c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "packed_dataframe = await client.select_time_series(\"lsst.sal.ESS.accelerometer\", [\"*\"], start, end)\n",
    "\n",
    "az = await client.select_time_series('lsst.sal.MTMount.azimuth', \\\n",
    "                                        ['actualPosition', 'actualVelocity', 'actualTorque', 'timestamp'],  start, end)\n",
    "el = await client.select_time_series('lsst.sal.MTMount.elevation', \\\n",
    "                                        ['actualPosition', 'actualVelocity', 'actualTorque', 'timestamp'],  start, end)\n",
    "\n",
    "\n",
    "azPos = await client.select_time_series('lsst.sal.MTMount.logevent_azimuthInPosition', \\\n",
    "                                            ['inPosition', 'private_kafkaStamp'],  start, end)\n",
    "\n",
    "try:\n",
    "    azPos = azPos[azPos['inPosition']] \n",
    "except:\n",
    "    print(\"No inpos event\")\n",
    "    \n",
    "elPos = await client.select_time_series('lsst.sal.MTMount.logevent_elevationInPosition', \\\n",
    "                                            ['inPosition', 'private_kafkaStamp'],  start, end)\n",
    "\n",
    "try:\n",
    "    elPos = elPos[elPos['inPosition']]\n",
    "except:\n",
    "    print(\"No inpos event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f2bab-8930-413f-88d4-65b180f58d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az_track = await client.select_time_series('lsst.sal.MTMount.command_trackTarget', \\\n",
    "                                            ['azimuth', 'taiTime'],  start, end)\n",
    "el_track = await client.select_time_series('lsst.sal.MTMount.command_trackTarget', \\\n",
    "                                            ['elevation', 'taiTime'],  start, end)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd440f-d2ee-4201-9920-b09fa5577764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query PSD \n",
    "psd =  await client.select_time_series(\"lsst.sal.ESS.accelerometerPSD\", [\"*\"], start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7e96b-ab84-4344-be94-12a383910d88",
   "metadata": {},
   "source": [
    "## Build a dataframe with all accelerometers data and rendezvous it with the MTMount data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff75e1-fd78-4d87-a154-c41db0f90497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accel_df = build_df_with_all_accelerometers(packed_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ffdcf-6406-4e88-9d5b-6da9e549d72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rolling_average='1s' # Smooths the noisy data ?  \n",
    "\n",
    "accel_df.index = pd.DatetimeIndex(accel_df.index)\n",
    "accel_df = accel_df.sort_index()\n",
    "\n",
    "accel_df = accel_df.rolling(rolling_average, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6485d7d-275d-4a9a-9e53-c2626cbf3476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az_df = rendezvous_dataframes(az, accel_df)\n",
    "el_df = rendezvous_dataframes(el, accel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d19820-7c7d-43f9-b977-4ceaacd2f7a9",
   "metadata": {},
   "source": [
    "# Read in HDF5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7124e5-c67c-457f-9660-dfc19c83925d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, time, os, asyncio\n",
    "import scipy.stats as stats\n",
    "from scipy import signal\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f15cc-da0b-4289-b811-fedb633a58b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "f1= h5py.File('M1M3-2023-05-26T00:00.hdf', 'r') \n",
    "list(f1.keys())\n",
    "X1 = f1['1 X']\n",
    "X2 =f1['2 X']\n",
    "# df1= np.array(X1.value)\n",
    "# dfy1= np.array(y1.value)\n",
    "# print (df1.shape)\n",
    "# print (dfy1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58efa81-1546-4244-8932-1dcc39cc7e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_hdf(fname, t_range=None):\n",
    "    f = h5py.File(fname, 'r')\n",
    "    times = f['timestamp']\n",
    "    if t_range is None:\n",
    "        max_x = f['1 X'][::1].argmax()\n",
    "        ndx_filt = [int(max_x-1e4), int(max_x+1e4), 1]\n",
    "    else:\n",
    "        full_times = times[::1]\n",
    "        t_ndx = lambda x : np.argmin(np.abs(x - full_times))   # Find the index that is closest to the given timestamp\n",
    "        t_start = t_ndx(t_range[0])\n",
    "        t_end = t_ndx(t_range[1])\n",
    "        del full_times # Explicitly delete the data to make sure we aren't using too much memory\n",
    "        print(f\"Using (index, timestamp):  ({t_start}, {t_range[0]}) and ({t_end}, {t_range[1]})\")\n",
    "        ndx_filt = [int(t_start), int(t_end), 1]\n",
    "    time_subset = times[ndx_filt[0]:ndx_filt[1]:ndx_filt[2]]\n",
    "    num_times = np.sum(time_subset > 0) # String of 0s at the end of file that we don't want to read in\n",
    "    treal = time_subset[:num_times] - time_subset[0]\n",
    "    \n",
    "    mkeys = [1,2,3]\n",
    "    dkeys = 'XYZ'\n",
    "    all_data = np.zeros((3,3,num_times))\n",
    "    key_data = {}\n",
    "\n",
    "    for i,m in enumerate(mkeys):\n",
    "        for j,d in enumerate(dkeys):\n",
    "            key = f'{m} {d}'\n",
    "            dload = f[key]\n",
    "            key_data[i,j] = key # Convenience object to map from [i,j] to data set\n",
    "            all_data[i,j] = dload[ndx_filt[0]:ndx_filt[1]:ndx_filt[2]][:num_times]\n",
    "    f.close()\n",
    "    return all_data, key_data, time_subset[:num_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0753eb7-5165-4d54-8d70-fddca674566a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get full start-end range\n",
    "# hdf_data, key_order, hd_time = open_hdf('/home/a/adari/DATA/Rotator-2023-05-15T00_00.hdf', t_range=(start.to_value('unix'), end.to_value('unix')))\n",
    "\n",
    "# Get 2 second range\n",
    "hdf_data, key_order, hd_time = open_hdf('./M1M3-2023-05-26T00:00.hdf', t_range=(start.to_value('unix'),start.to_value('unix') + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe52253-3137-49fd-911f-9be8b5e3921f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T04:17:57.471442Z",
     "iopub.status.busy": "2023-05-26T04:17:57.471059Z",
     "iopub.status.idle": "2023-05-26T04:17:57.474146Z",
     "shell.execute_reply": "2023-05-26T04:17:57.473672Z",
     "shell.execute_reply.started": "2023-05-26T04:17:57.471424Z"
    },
    "tags": []
   },
   "source": [
    "# Query M1M3 and TMA timestamp events:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe062c2-5b98-45d7-9303-11569ae9c0aa",
   "metadata": {},
   "source": [
    "First we could query to know if the M1M3 was in a state where it's publishing data into the EFD.(Enabled, Disabled or Fault, NOT Offline or Standby) Otherwise, there'll be no further telemetry.  \n",
    "These events are only published in the event changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def6ada-767d-438b-8f3d-e07647f77581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summarystate = await client.select_time_series(\n",
    "    \"lsst.sal.MTM1M3.logevent_summaryState\", \n",
    "    \"*\", \n",
    "    Time(start, format=\"isot\", scale=\"utc\"),\n",
    "    Time(end, format=\"isot\", scale=\"utc\"), \n",
    ")\n",
    "\n",
    "df_summarystate[\"summaryState\"] = \\\n",
    "    df_summarystate[\"summaryState\"].map(lambda x: MTM1M3.DetailedState(x).name)\n",
    "\n",
    "df_summarystate = df_summarystate.set_index(\"private_rcvStamp\")\n",
    "df_summarystate.index = pd.to_datetime(df_summarystate.index, unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fdfac-b473-455a-b8d8-309db30b4c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summarystate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a45e0-1191-410d-aab3-d71e3fda135e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_state = await client.select_time_series(\n",
    "    \"lsst.sal.MTM1M3.logevent_detailedState\", \n",
    "    \"*\", \n",
    "    Time(start, format=\"isot\", scale=\"utc\"),\n",
    "    Time(end, format=\"isot\", scale=\"utc\"), \n",
    ")\n",
    "\n",
    "df_state[\"detailedStateName\"] = \\\n",
    "    df_state[\"detailedState\"].map(lambda x: MTM1M3.DetailedState(x).name)\n",
    "\n",
    "df_state = df_state.set_index(\"private_rcvStamp\")\n",
    "df_state.index = pd.to_datetime(df_state.index, unit=\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e15480-8272-4246-878e-56cae813425d",
   "metadata": {},
   "source": [
    "ACTIVEENGINEERING is the time when the mirror was raised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654bd8a-f696-44e4-a3ca-73f2f933cc93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "when_parked = df_state[df_state[\"detailedStateName\"] == \"PARKED\"].index\n",
    "when_rasing = df_state[df_state[\"detailedStateName\"] == \"RAISINGENGINEERING\"].index\n",
    "when_lowering = df_state[df_state[\"detailedStateName\"] == \"LOWERINGENGINEERING\"].index\n",
    "when_active = df_state[df_state[\"detailedStateName\"] == \"ACTIVEENGINEERING\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71a419-8694-458a-ae1d-d1179f22d09c",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33112e80-2f50-4fe2-bc58-9f41aa30d60d",
   "metadata": {},
   "source": [
    "## PSD before and after an event time (https://jira.lsstcorp.org/browse/FRACAS-158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7985f-aec0-4864-aace-19d12d450166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to fix column names etc\n",
    "def fix_pd(dataframe, field, sensor):\n",
    "    df = dataframe\n",
    "    df = df.loc[psd.sensorName == sensor]\n",
    "    df = df.filter(regex=f\"PSD{field}\")\n",
    "    df = df.reindex(sorted(df.columns, key=lambda x: float(x[16:])), axis=1)\n",
    "    # rename all columns \n",
    "    x = np.arange(0,201)\n",
    "    dictionary = dict(zip(df.columns, x))\n",
    "    df.rename(columns=dictionary,\n",
    "          inplace=True)\n",
    "    del df[0]\n",
    "    #series = df.sum(axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6c926-2d23-4f44-aed2-3b7a5e23eeb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter psd dataframe before and after the vibrations event\n",
    "event_time = \"2023-05-30T21:14:53\"\n",
    "beg = \"2023-05-30T21:13:50\"\n",
    "end = \"2023-05-30T21:15:50\"\n",
    "\n",
    "before = psd[(psd.index<event_time) & (psd.index > beg)]\n",
    "after = psd[(psd.index>event_time) & (psd.index < end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a3d5b-a7cc-4558-97a6-e3e5da72528e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.suptitle(f\"Accelerometer accelerations vs Azimuth\")\n",
    "\n",
    "for sensorName in sensorNames:\n",
    "    fig, axs = plt.subplots(nrows = 2,ncols = 3, figsize = (16,8))\n",
    "\n",
    "    for i, baseField in enumerate(baseFields):\n",
    "        # Before all filter in a single axis. \n",
    "        axs[0,i].set_title(f'{baseField[-1]} PSD before(30 sec)')\n",
    "        data_before = fix_pd(before, baseField[-1],sensorName)\n",
    "        axs[0,i].plot(data_before.T, linestyle='-')\n",
    "        axs[0,2].legend(data_before.index, bbox_to_anchor=(1.05, 1.05), borderaxespad=0, ncols=2)\n",
    "\n",
    "\n",
    "        ### After all sensors in a single axis. \n",
    "        axs[1,i].set_title(f'{baseField[-1]} PSD after (30 sec)')\n",
    "        data_after = fix_pd(after, baseField[-1],sensorName)\n",
    "        axs[1,i].plot(data_after.T,linestyle='--')\n",
    "        axs[1,2].legend(data_after.index, bbox_to_anchor=(1.05, 1.05), borderaxespad=0, ncols=2)\n",
    "        \n",
    "        fig.supylabel(\"Acceleration PSD [m$^2$/(Hz$^2$ s$^4$)] \")\n",
    "        fig.supxlabel(\"Frequency [Hz]\")\n",
    "        plt.grid(False)\n",
    "        \n",
    "        fig.suptitle(f\"PSD before and after {event_time} ---- {sensorName}\")\n",
    "        fig.savefig(f\"./30s_PSD_before_and_after {sensorName}.pdf\", bbox_inches='tight')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b478ca4-1d7d-4f56-a6cc-e26651bbf091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f1bcc-7f9c-422e-b30d-cf9bf3bf5cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22966ed4-90fc-4630-a09a-066fb2fd303f",
   "metadata": {},
   "source": [
    "## Accelerometers readings in each axes vs azimuth and elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c89cc-66f0-425d-8f54-f133c9b1f798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1,ncols = 3, figsize = (14,4))\n",
    "\n",
    "#plt.suptitle(f\"Accelerometer accelerations vs Azimuth\")\n",
    "\n",
    "for i, baseField in enumerate(baseFields):\n",
    "    for col in az_df:\n",
    "        if (baseField[-1]) in col:\n",
    "            plt.subplot(1,3,i+1)\n",
    "            plt.title(f'{baseField[-1]} accelerations')\n",
    "            plt.plot(az_df['actualPosition'], az_df[col], linestyle='--', marker='o', label=f'{sensorNames[int(col[-1])]}')\n",
    "            \n",
    "            plt.ylabel(\"Accel [m/s2]\")\n",
    "            plt.xlabel(\"Azimuth [deg]\")\n",
    "\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5438b3-5e07-4dcf-8a14-e819a6c726f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1,ncols = 3, figsize = (14,4))\n",
    "\n",
    "#plt.suptitle(f\"Accelerometer accelerations vs Azimuth\")\n",
    "\n",
    "for i, baseField in enumerate(baseFields):\n",
    "    for col in el_df:\n",
    "        if (baseField[-1]) in col:\n",
    "            plt.subplot(1,3,i+1)\n",
    "            plt.title(f'{baseField[-1]} accelerations')\n",
    "            plt.plot(el_df['actualPosition'], el_df[col], linestyle='--', marker='o', label=f'{sensorNames[int(col[-1])]}')\n",
    "            \n",
    "            plt.ylabel(\"Accel [m/s2]\")\n",
    "            plt.xlabel(\"Elevation [deg]\")\n",
    "\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93627df7-070b-4104-be93-9923863452a9",
   "metadata": {},
   "source": [
    "## El vs Az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097da38b-d79c-4393-87ae-a4afdb2fcf98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (4,4))\n",
    "ax.set_ylabel('Elevation [deg]', fontsize=12)\n",
    "ax.set_xlabel('Azimuth [deg]', fontsize=12)\n",
    "plt.plot(az['actualPosition'], el['actualPosition'], label=\"MTMount trajectory EL vs AZ \\n when oscillations were seen\")\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677de61a-dbab-4dde-ba31-edcc2fd7df58",
   "metadata": {},
   "source": [
    "## Timeline: Az velocity with Accelerometers X, Y and Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668723a-b026-4b3b-a3e4-409a2643b64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yr_cen=np.median(el['actualTorque'])\n",
    "dy=1.1*(np.max(el['actualTorque'])- np.min(el['actualTorque']))\n",
    "\n",
    "p = figure(x_axis_type='datetime', y_range=(yr_cen-dy, yr_cen+dy), plot_width=1200, plot_height=800)\n",
    "\n",
    "p.yaxis.axis_label = \"Velocity [deg/s]\"\n",
    "p.xaxis.axis_label = \"Time\"\n",
    "p.title = \"AZ Velocity and Accelerometer X,Y and Z (m/s2) \\n\"\n",
    "\n",
    "# AZ velocity\n",
    "p.line(x=(Time(az.index.values)).value, \n",
    "        y=az['actualTorque'], \n",
    "        color='blue', alpha=0.5, \n",
    "        legend_label='MTMount Measured Az Torque')\n",
    "\n",
    "p.line(x=(Time(el.index.values)).value, \n",
    "        y=el['actualTorque'], \n",
    "        color='blue', alpha=0.5, \n",
    "        legend_label='MTMount Measured EL Torque')\n",
    "\n",
    "\n",
    "# Accelerometers\n",
    "p.extra_y_ranges = {'Accelerometers': Range1d(start=-3, end=12)}\n",
    "p.add_layout(LinearAxis(y_range_name='Accelerometers', axis_label='Accel [m/s^2]'), 'right')\n",
    "\n",
    "for i, sensorName in enumerate(sensorNames):\n",
    "    sub_dataframe = packed_dataframe.loc[packed_dataframe.sensorName==sensorName]\n",
    "    for baseField in baseFields:\n",
    "        df = merge_packed_time_series(sub_dataframe, baseField, stride=1,\n",
    "                             ref_timestamp_col=\"timestamp\", fmt='unix_tai',\n",
    "                             scale='tai')\n",
    "        p.line(x=(Time(df.index.values)).value, \n",
    "               y=df[baseField], \n",
    "               color=colours[i], alpha=0.5, \n",
    "               y_range_name = 'Accelerometers',\n",
    "               legend_label=f\"{list(baseField[-1])} {sensorName}\")\n",
    "\n",
    "\n",
    "#p.legend.location = 'bottom_left'\n",
    "p.legend.click_policy = 'hide'\n",
    "show_in_pos(azPos)\n",
    "#show_track_command(az_track)\n",
    "\n",
    "show(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeeb9da-f858-449d-8f6f-bc633d1c965d",
   "metadata": {},
   "source": [
    "## Timeline: EL velocity timeline with Accelerometers X, Y and Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3216b-fe8b-4da9-a401-189aa678c9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yr_cen=np.median(el['actualVelocity'])\n",
    "dy=1.1*(np.max(el['actualVelocity'])- np.min(el['actualVelocity']))\n",
    "\n",
    "p = figure(x_axis_type='datetime', y_range=(yr_cen-dy, yr_cen+dy), plot_width=1200, plot_height=800)\n",
    "p.yaxis.axis_label = \"Velocity [deg/s]\"\n",
    "p.xaxis.axis_label = \"Time\"\n",
    "p.title = \"EL Velocity and Accelerometers X,Y and Z (m/s2) \\n\"\n",
    "\n",
    "# AZ velocity\n",
    "p.line(x=(Time(el.index.values)).value, \n",
    "        y=el['actualVelocity'], \n",
    "        color='blue', alpha=0.5, \n",
    "        legend_label='MTMount Measured EL Velocity')\n",
    "\n",
    "\n",
    "# Accelerometers\n",
    "p.extra_y_ranges = {'Accelerometers': Range1d(start=-3, end=12)}\n",
    "p.add_layout(LinearAxis(y_range_name='Accelerometers', axis_label='Accel [m/s^2]'), 'right')\n",
    "\n",
    "for i, sensorName in enumerate(sensorNames):\n",
    "    sub_dataframe = packed_dataframe.loc[packed_dataframe.sensorName==sensorName]\n",
    "    for baseField in baseFields:\n",
    "        df = merge_packed_time_series(sub_dataframe, baseField, stride=1,\n",
    "                             ref_timestamp_col=\"timestamp\", fmt='unix_tai',\n",
    "                             scale='tai')\n",
    "        p.line(x=(Time(df.index.values)).value, \n",
    "               y=df[baseField], \n",
    "               color=colours[i], alpha=0.5, \n",
    "               y_range_name = 'Accelerometers',\n",
    "               legend_label=f\"{list(baseField[-1])} {sensorName}\")\n",
    "\n",
    "#p.legend.location = 'bottom_left'\n",
    "p.legend.click_policy = 'hide'\n",
    "#show_in_pos(elPos)\n",
    "\n",
    "show(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c605d-2bad-4569-ad45-4b05675e3af9",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977f468-ec1d-45da-916b-1a0b1e614c7c",
   "metadata": {},
   "source": [
    "### Time Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a84e6-7189-458e-b29a-172f62d1ed53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "corr_matrix = accel_df.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=np.bool))\n",
    "#heatmap = sn.heatmap(corr_matrix, annot=True, mask = mask, cmap=\"PiYG\")\n",
    "ax = sn.heatmap(corr_matrix, annot=True, mask = mask, cmap=\"PiYG\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.title(\"Accelerations Correlation Matrix\")\n",
    "conversion_text = (\"\\n\".join(f\"sensor{i} = {sensorNames[i]}\" for i in range(4)))\n",
    "plt.text(0.7, 0.95, conversion_text , transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5833fc-ce02-4989-981e-1f8d8aa15926",
   "metadata": {},
   "source": [
    "### Frequency domain - better with PSD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d14722-0d58-4805-a058-d982500e5db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build data frame with FFT for each accelerometer sensor and channel\n",
    "fft_df = pd.DataFrame()\n",
    "for column in accel_df:\n",
    "    col = accel_df[column]\n",
    "\n",
    "    frate = 1.0 / 200.0\n",
    "    \n",
    "    Pfft = np.fft.fft(col)\n",
    "    N = len(Pfft)\n",
    "    \n",
    "    freqs = np.fft.fftfreq(len(Pfft), frate)\n",
    "    \n",
    "    fft_df[f'{column}_freq'] = freqs\n",
    "    fft_df[f'{column}_Pfft'] = Pfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d55eb5-9fad-421e-af79-b92f9227067d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "frate = 1. / 200\n",
    "Pfft = np.fft.fft(accel_df['X_sensor0'])\n",
    "N = len(Pfft)\n",
    "# Pfft[0] = 0  # Set huge DC component to zero, equates to Pressure = Pressure - numpy.mean(Pressure)\n",
    "\n",
    "freqs = np.fft.fftfreq(len(Pfft), frate)\n",
    "#freqs2 = np.fft.fftfreq(len(Pfft), 1. / frate)\n",
    "\n",
    "plt.plot(freqs, Pfft)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76320528-383d-41a3-b7a1-153e1b02546a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "corr_matrix = fft_df.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=np.bool))\n",
    "ax = sn.heatmap(corr_matrix, annot=True, mask = mask, cmap=\"PiYG\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.title(\"Accelerations Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3e591-c0bf-4ed4-854f-711a9e231178",
   "metadata": {},
   "source": [
    "## Rotator Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d544976-b8b5-4161-a799-6db52a5684f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hdf_data, key_order, hd_time = open_hdf('/home/a/adari/DATA/Rotator-2023-05-15T00_00.hdf', t_range=(start.to_value('unix'),start.to_value('unix') + 2.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab00841-40a8-4176-a57f-c08158b3509a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "times = [datetime.datetime.fromtimestamp(x).strftime(\"%x %X\") for x in hd_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca8c14-f85e-4b0d-a980-b0032ca50a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Taking perfectly even sampling\n",
    "fs = round(1/np.mean(np.diff(hd_time)))\n",
    "dkey = (0,0)\n",
    "ax[0].plot(hd_time, hdf_data[dkey], '.')\n",
    "ax[1].specgram(hdf_data[0,0], Fs=fs)\n",
    "\n",
    "fig.suptitle(f\"Data and Spectrogram of {key_order[dkey]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05ff2c-560c-49a5-9142-a28db2be3292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hdf_data, key_order, hd_time = open_hdf('/home/a/adari/DATA/Rotator-2023-05-15T00_00.hdf', t_range=(start.to_value('unix'),start.to_value('unix') + 20.1))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Taking perfectly even sampling\n",
    "fs = round(1/np.mean(np.diff(hd_time)))\n",
    "dkey = (0,0)\n",
    "ax[0].plot(hd_time, hdf_data[dkey], '.')\n",
    "ax[1].specgram(hdf_data[0,0], Fs=fs)\n",
    "\n",
    "fig.suptitle(f\"Data and Spectrogram of M1M3 {key_order[dkey]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27adf0d-e4c8-4db1-b538-01519aee126e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8bcbc-a3cd-42a9-b55e-e4c111e655d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,markdown//md"
  },
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
