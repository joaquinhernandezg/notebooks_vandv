{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8799582-f047-4389-91fb-e66295a3be9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, time, os, asyncio\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import signal\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "from lsst.summit.utils.tmaUtils import TMAEventMaker, TMAState\n",
    "from lsst.summit.utils.efdUtils import getEfdData, makeEfdClient, clipDataToEvent, calcNextDay\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d64e0-7f1a-4e77-83d7-8c70b492cbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_freq_psd(vals, timestep):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the frequency power spectrum of a signal.\n",
    "\n",
    "    Args:\n",
    "        vals (np.array): The signal values.\n",
    "        timestep (float): The time step between samples.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The frequencies and power spectral density.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove the mean from the signal.\n",
    "\n",
    "    meanval = np.mean(vals)\n",
    "    signal = vals - meanval\n",
    "\n",
    "    # Calculate the length of the signal.\n",
    "\n",
    "    N = len(signal)\n",
    "\n",
    "    # Calculate the power spectral density.\n",
    "\n",
    "    psd = np.abs(np.fft.rfft(np.array(signal) * 1)) ** 2\n",
    "\n",
    "    # Calculate the frequencies.\n",
    "\n",
    "    frequencies = np.fft.rfftfreq(N, timestep)\n",
    "\n",
    "    return (frequencies, psd)\n",
    "\n",
    "def get_efd_data(begin, end, client):\n",
    "\n",
    "    \"\"\"Extract all the MTMount data from the EFD and add to dict.\n",
    "\n",
    "    Args:\n",
    "        begin (str): The start time of the query.\n",
    "        end (str): The end time of the query.\n",
    "        client (object): influx client\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the MTMount data.\n",
    "    \"\"\"\n",
    "\n",
    "    query_dict = {}\n",
    "\n",
    "    query_dict[\"el\"] = getEfdData(\n",
    "        client,\n",
    "        \"lsst.sal.MTMount.elevation\",\n",
    "        columns=[\"private_sndStamp\", \"private_efdStamp\", \"actualPosition\", \"actualVelocity\", \"actualTorque\"],\n",
    "        begin=begin,\n",
    "        end=end,\n",
    "        prePadding=0,\n",
    "        postPadding=0,\n",
    "        warn=False,\n",
    "    )\n",
    "    query_dict[\"az\"] = getEfdData(\n",
    "        client,\n",
    "        \"lsst.sal.MTMount.azimuth\",\n",
    "        columns=[\"private_sndStamp\", \"private_efdStamp\", \"actualPosition\", \"actualVelocity\", \"actualTorque\"],\n",
    "        begin=begin,\n",
    "        end=end,\n",
    "        prePadding=0,\n",
    "        postPadding=0,\n",
    "        warn=False,\n",
    "    )\n",
    "    return query_dict\n",
    "\n",
    "def get_vms_data(filename, begin_time, end_time, key_dict):\n",
    "\n",
    "    \"\"\"Extract VMS data from a HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the HDF5 file.\n",
    "        begin_time (float): The start time of the query (unix, utc).\n",
    "        end_time (float): The end time of the query (unix, utc).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A Pandas DataFrame containing the VMS data.\n",
    "    \"\"\"\n",
    "\n",
    "    f = h5py.File(filename, 'r')\n",
    "    times = f['timestamp'][::1]\n",
    "    mkeys = [1, 2, 3]\n",
    "    dkeys = 'XYZ'\n",
    "    sel = (times > begin_time) & (times < end_time)\n",
    "    data_dict = {}\n",
    "    data_dict['times'] = times[sel]  \n",
    "    for i, m in enumerate(mkeys):\n",
    "        for j, d in enumerate(dkeys):\n",
    "            key = f'{m} {d}'\n",
    "            data_dict[key_dict[key]] = f[key][::1][sel]\n",
    "    data_frame = pd.DataFrame(data_dict)\n",
    "    return data_frame\n",
    "\n",
    "def get_peak_points(freq, psd, height=0.01):\n",
    "    \"\"\"\n",
    "    Get the peak points of the power spectral density (PSD).\n",
    "\n",
    "    Args:\n",
    "        freq (numpy.ndarray): The frequency vector.\n",
    "        psd (numpy.ndarray): The power spectral density.\n",
    "        height (float): The minimum peak height.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The peak points.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the peak indices and heights.\n",
    "    peak_ind, peak_dict = find_peaks(psd, height=height)\n",
    "    peaks = freq[peak_ind]\n",
    "\n",
    "    # If there are no peaks, return None.\n",
    "    if len(peaks) < 1:\n",
    "        return None\n",
    "\n",
    "    # Find the sub-peaks within each group of peaks that are close in frequency.\n",
    "    points = []\n",
    "    for i, peak in enumerate(peaks):\n",
    "        sel = (abs(peaks - peak) < 1)\n",
    "        sub_peaks = peaks[sel]\n",
    "        sub_heights = peak_dict['peak_heights'][sel]\n",
    "        points.append(sub_peaks[np.argmax(sub_heights)])\n",
    "\n",
    "    # Return the unique peak points.\n",
    "    return np.unique(np.array(points))\n",
    "\n",
    "def get_vms_data(filename, begin_time, end_time, key_dict):\n",
    "\n",
    "    \"\"\"Extract VMS data from a HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the HDF5 file.\n",
    "        begin_time (float): The start time of the query (unix, utc).\n",
    "        end_time (float): The end time of the query (unix, utc).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A Pandas DataFrame containing the VMS data.\n",
    "    \"\"\"\n",
    "\n",
    "    f = h5py.File(filename, 'r')\n",
    "    times = f['timestamp'][::1]\n",
    "    if \"m1m3\" in sorted(key_dict.values())[0]:\n",
    "        mkeys = [1, 2, 3]\n",
    "        dkeys = 'XYZ'\n",
    "    if \"m2\" in sorted(key_dict.values())[0]:\n",
    "        mkeys = [1, 2, 3, 4, 5, 6]\n",
    "        dkeys = 'XYZ'\n",
    "    sel = (times > begin_time) & (times < end_time)\n",
    "    data_dict = {}\n",
    "    data_dict['times'] = times[sel]  \n",
    "    for i, m in enumerate(mkeys):\n",
    "        for j, d in enumerate(dkeys):\n",
    "            key = f'{m} {d}'\n",
    "            data_dict[key_dict[key]] = f[key][::1][sel]\n",
    "    data_frame = pd.DataFrame(data_dict)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304fcb3-3700-4f53-b50f-0a3516acfff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_m1m3_dict={'1 X': 'm1m3_x_1', \n",
    "          '1 Y': 'm1m3_y_1', \n",
    "          '1 Z': 'm1m3_z_1', \n",
    "          '2 X': 'm1m3_x_2', \n",
    "          '2 Y': 'm1m3_z_2', \n",
    "          '2 Z': 'm1m3_y_2', \n",
    "          '3 X': 'm1m3_x_3', \n",
    "          '3 Y': 'm1m3_y_3', \n",
    "          '3 Z': 'm1m3_z_3'\n",
    "}\n",
    "vms_m1m3_filename=\"/home/p/pferguso/u/scratch/M1M3-2023-06-28T0000.hdf\"\n",
    "\n",
    "key_m2_dict={'1 X': 'm2_x_1', \n",
    "          '1 Y': 'm2_y_1', \n",
    "          '1 Z': 'm2_z_1', \n",
    "          '2 X': 'm2_x_2', \n",
    "          '2 Y': 'm2_z_2', \n",
    "          '2 Z': 'm2_y_2', \n",
    "          '3 X': 'm2_x_3', \n",
    "          '3 Y': 'm2_z_3', \n",
    "          '3 Z': 'm2_y_3', \n",
    "          '4 X': 'm2_x_4', \n",
    "          '4 Y': 'm2_y_4', \n",
    "          '4 Z': 'm2_z_4', \n",
    "          '5 X': 'm2_x_5', \n",
    "          '5 Y': 'm2_z_5', \n",
    "          '5 Z': 'm2_y_5',\n",
    "          '6 X': 'm2_x_6', \n",
    "          '6 Y': 'm2_z_6', \n",
    "          '6 Z': 'm2_y_6', \n",
    "}\n",
    "vms_m2_filename=\"/home/p/pferguso/u/scratch/M2-2023-06-28T00:00.hdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e4b41-7c5d-4480-9211-f2562bc4a4d2",
   "metadata": {},
   "source": [
    "### setup tma events\n",
    "\n",
    "For this test we wanted, force balance on, mirror raised, and no slew\n",
    "for the time range '2023-06-28 00:13:30'- '2023-06-28 00:15:00'\n",
    "\n",
    "- assuming \"lsst.sal.MTM1M3.appliedBalanceForces\" being nonzero means the force balance is on then: https://usdf-rsp.slac.stanford.edu/chronograf/sources/1/chronograf/data-explorer?query=SELECT%20%22fx%22%2C%20%22fy%22%2C%20%22fz%22%20FROM%20%22efd%22.%22autogen%22.%22lsst.sal.MTM1M3.appliedBalanceForces%22%20WHERE%20time%20%3E%20%3AdashboardTime%3A%20AND%20time%20%3C%20%3AupperDashboardTime%3A#\n",
    "- mirror was raised at 06/27/2023 19:39:10 and not lowered according to \"lsst.sal.MTM1M3.command_raiseM1M3\"\n",
    "- telescope was between slews\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd0c6b-841a-4bdb-ae53-39c48825a778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dayObs=20230628\n",
    "eventMaker = TMAEventMaker()\n",
    "events = eventMaker.getEvents(dayObs)\n",
    "slews=[e for e in events if e.type==TMAState.SLEWING]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f65cde-ec61-45bd-bdd2-20fb79560b66",
   "metadata": {},
   "source": [
    "### query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177723f9-f1fe-4637-ab4d-29aff76be100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "begin_time=Time('2023-06-28 00:13:30', format=\"iso\", scale=\"utc\")\n",
    "end_time=Time('2023-06-28 00:15:00', format=\"iso\", scale=\"utc\")\n",
    "efd_dict=get_efd_data(begin_time, end_time, eventMaker.client)\n",
    "vms_m1m3_data=get_vms_data(vms_m1m3_filename, begin_time.unix, end_time.unix, key_dict=key_m1m3_dict)\n",
    "vms_m2_data=get_vms_data(vms_m2_filename, begin_time.unix, end_time.unix, key_dict=key_m2_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726ebe5-a4a6-4653-bf5e-e45784826e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute quadratic sum of accelerations in each channel\n",
    "for j in np.arange(3) +1:\n",
    "    vms_m1m3_data[f\"total_{j}\"] = np.linalg.norm(vms_m1m3_data[[f\"m1m3_{i}_{j}\" for i in [\"x\",\"y\",\"z\"]]].values, axis=1)\n",
    "\n",
    "for j in np.arange(6) + 1: \n",
    "    vms_m2_data[f\"total_{j}\"] = np.linalg.norm(vms_m2_data[[f\"m2_{i}_{j}\" for i in [\"x\",\"y\",\"z\"]]].values, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6acc2-2e2a-4c98-b507-1ef4fb6aa905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T00:19:22.529466Z",
     "iopub.status.busy": "2023-08-31T00:19:22.529104Z",
     "iopub.status.idle": "2023-08-31T00:19:23.853646Z",
     "shell.execute_reply": "2023-08-31T00:19:23.852789Z",
     "shell.execute_reply.started": "2023-08-31T00:19:22.529440Z"
    },
    "tags": []
   },
   "source": [
    "### Plots\n",
    " - First plot is just plotting the vms data (and elevation telemetry)\n",
    " - second plot is spectrograms of the vms data\n",
    " - third plot a psd of all the vms data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378942d-99ad-4e38-ba78-cf5199d349ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(3, dpi=175, sharex=True, figsize=(10,5))\n",
    "plt.suptitle(f\"M1M3\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\\nForce Balance on, mirror raised, not slewing\", y=0.99)\n",
    "ax=axs[0]\n",
    "for i in np.arange(3):\n",
    "\n",
    "    axs[0].plot((Time(vms_m1m3_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m1m3_data[f\"m1m3_x_{i+1}\"]  - 0.002 * i,\n",
    "               label=f\"m1m3_x_{i+1}\")\n",
    "    axs[1].plot((Time(vms_m1m3_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m1m3_data[f\"m1m3_y_{i+1}\"] - 0.002 * i,\n",
    "               label=f\"m1m3_y_{i+1}\")\n",
    "    axs[2].plot((Time(vms_m1m3_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m1m3_data[f\"m1m3_z_{i+1}\"] - 0.002 * i,\n",
    "               label=f\"m1m3_z_{i+1}\"\n",
    "\n",
    "              )\n",
    "for i in np.arange(3):\n",
    "    axs[i].legend(ncol=3, edgecolor=\"white\", loc=9)\n",
    "    axs[i].set_ylabel(\"acceleration\\n[m/s^2]\")\n",
    "    axs[i].set_ylim(-0.005,0.003)\n",
    "axs[2].set_xlabel(\"Time [s]\")\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.savefig(f'./vms_look_m1m3_{begin_time.iso.replace(\" \", \".\").replace(\":\",\"-\")[:-4]}.png', facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8939a-123e-4587-9ace-2ad8c7af42fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(3, dpi=175, sharex=True, figsize=(10,5))\n",
    "plt.suptitle(f\"M2\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\\nForce Balance on, mirror raised, not slewing\", y=0.99)\n",
    "ax=axs[0]\n",
    "for i in np.arange(6):\n",
    "\n",
    "    axs[0].plot((Time(vms_m2_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m2_data[f\"m2_x_{i+1}\"]  - 0.001 * i - np.mean(vms_m2_data[f\"m2_x_{i+1}\"]),\n",
    "               label=f\"m2_x_{i+1}\")\n",
    "    axs[1].plot((Time(vms_m2_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m2_data[f\"m2_y_{i+1}\"] - 0.001 * i - np.mean(vms_m2_data[f\"m2_y_{i+1}\"]),\n",
    "               label=f\"m2_y_{i+1}\")\n",
    "    axs[2].plot((Time(vms_m2_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m2_data[f\"m2_z_{i+1}\"] - 0.001 * i - np.mean(vms_m2_data[f\"m2_z_{i+1}\"]),\n",
    "               label=f\"m2_z_{i+1}\"\n",
    "\n",
    "              )\n",
    "for i in np.arange(3):\n",
    "    axs[i].legend(ncol=6, edgecolor=\"white\", loc=9)\n",
    "    axs[i].set_ylabel(\"acceleration\\n[m/s^2]\")\n",
    "    axs[i].set_ylim(-0.006,0.004)\n",
    "axs[2].set_xlabel(\"Time [s]\")\n",
    "plt.savefig(f'./vms_look_m2_{begin_time.iso.replace(\" \", \".\").replace(\":\",\"-\")[:-4]}.png', facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a31ba2-5f4c-483b-8d70-7f85f27a603e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=175)\n",
    "plt.suptitle(f\"M1M3\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\\nForce Balance on, mirror raised, not slewing\", y=0.99)\n",
    "step=0.1\n",
    "for i,key in enumerate([i for i in sorted(key_m1m3_dict.values()) if (\"m1m3\" in i)]):\n",
    "    \n",
    "    freq,psd=get_freq_psd(vms_m1m3_data[key], np.mean(np.diff(vms_m1m3_data[\"times\"])))\n",
    "    points_x=get_peak_points(freq, psd)\n",
    "    if points_x is not None:\n",
    "        points_y=np.ones_like(points_x) * i * step * -1\n",
    "        print(f\"{key}: {str([int(i) for i in points_x])[1:-1]} Hz\")\n",
    "    else: \n",
    "        print(f\"{key} no peaks\")\n",
    "    plt.plot(freq,psd - i * step, label=key, zorder=9, lw=1)\n",
    "\n",
    "plt.legend(ncol=3, edgecolor=\"k\", facecolor=\"white\", loc=9, framealpha=1)\n",
    "plt.ylim(-0.05 - i * step, 0.35)\n",
    "plt.xlabel(\"frequency [Hz]\")\n",
    "plt.ylabel(\"psd + offset\")\n",
    "plt.grid(visible=True, axis=\"x\", ls=\"dashed\", alpha=0.4)\n",
    "plt.xticks(np.arange(0,110,10))\n",
    "plt.savefig(\"./psd_m1m3_vms.png\", facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa168925-6737-44d6-9336-cf084342dfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "step=0.002\n",
    "for base in [\"x\",\"y\",\"z\"]:\n",
    "    plt.figure(dpi=175)\n",
    "    print(base)\n",
    "    plt.suptitle(f\"M2 {base}\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\\nForce Balance on, mirror raised, not slewing\", y=0.99)\n",
    "    for i,key in enumerate([i for i in sorted(key_m2_dict.values()) if ((\"m2\" in i) and (base in i))]):\n",
    "        print(key)\n",
    "        freq,psd=get_freq_psd(vms_m2_data[key], np.mean(np.diff(vms_m2_data[\"times\"])))\n",
    "        points_x=get_peak_points(freq, psd, height=0.001)\n",
    "        if points_x is not None:\n",
    "            points_y=np.ones_like(points_x) * i * step * -1\n",
    "            print(f\"{key}: {str([np.round(i,1) for i in points_x])[1:-1]} Hz\")\n",
    "        else: \n",
    "            print(f\"{key} no peaks\")\n",
    "        plt.plot(freq,psd - i * step, label=key, zorder=9, lw=0.8)\n",
    "    plt.legend(ncol=3, edgecolor=\"k\", facecolor=\"white\", loc=9, framealpha=1)\n",
    "    plt.ylim(-1 * step/4 - i * step, 2 * step)\n",
    "    plt.xlabel(\"frequency [Hz]\")\n",
    "    plt.ylabel(\"psd + offset\")\n",
    "    plt.grid(visible=True, axis=\"x\", ls=\"dashed\", alpha=0.4)\n",
    "    plt.xticks(np.arange(0,110,10))\n",
    "    plt.savefig(f\"./psd_m2_{base}_vms.png\", facecolor=\"white\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c68c9-39ab-4f88-b389-3e8d4e762ea5",
   "metadata": {},
   "source": [
    "### Plot psd of sum of accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ec256-48f8-4881-a841-76e90c88a9fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs=1/np.mean(np.diff(vms_m1m3_data[\"times\"]))\n",
    "fig,axs=plt.subplots(3, dpi=175, figsize=(10,4), sharex=True)\n",
    "plt.suptitle(f\"M1M3\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\", y=0.97)\n",
    "\n",
    "\n",
    "ax=axs[0]\n",
    "ax.specgram(vms_m1m3_data[\"total_1\"] - np.mean(vms_m1m3_data[\"total_1\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 1\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "ax=axs[1]\n",
    "ax.specgram(vms_m1m3_data[\"total_2\"] - np.mean(vms_m1m3_data[\"total_2\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 2\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "ax=axs[2]\n",
    "ax.specgram(vms_m1m3_data[\"total_3\"] - np.mean(vms_m1m3_data[\"total_3\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 3\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "plt.savefig(\"./spectrogram_total_accel_m1m3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51957f76-9495-4c7d-bd32-24dc88496f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs=1/np.mean(np.diff(vms_m2_data[\"times\"]))\n",
    "fig,axs=plt.subplots(6, dpi=175, figsize=(10,10), sharex=True)\n",
    "plt.suptitle(f\"M2\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\", y=0.97)\n",
    "\n",
    "\n",
    "ax=axs[0]\n",
    "ax.specgram(vms_m2_data[\"total_1\"] - np.mean(vms_m2_data[\"total_1\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 1\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "ax=axs[1]\n",
    "ax.specgram(vms_m2_data[\"total_2\"] - np.mean(vms_m2_data[\"total_2\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 2\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "ax=axs[2]\n",
    "ax.specgram(vms_m2_data[\"total_3\"] - np.mean(vms_m2_data[\"total_3\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 3\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "ax=axs[3]\n",
    "ax.specgram(vms_m2_data[\"total_4\"] - np.mean(vms_m2_data[\"total_4\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 4\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "ax=axs[4]\n",
    "ax.specgram(vms_m2_data[\"total_5\"] - np.mean(vms_m2_data[\"total_5\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 5\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "ax=axs[5]\n",
    "ax.specgram(vms_m2_data[\"total_6\"] - np.mean(vms_m2_data[\"total_6\"]), Fs=fs, detrend=\"mean\", vmin=-110)\n",
    "ax.set_ylabel(\"Channel 6\\nFreq [hz]\")\n",
    "ax.set_yticks(np.arange(25,125,25))\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b234a-f7fa-4477-afc2-90eab0114a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frame=vms_m1m3_data\n",
    "step=0.01\n",
    "cols=[i for i in data_frame.columns if \"total\" in i]\n",
    "plt.figure(dpi=175, figsize=(10,4))\n",
    "plt.title(f\"M1M3\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\")\n",
    "for i, key in enumerate(cols):\n",
    "    freq,psd=get_freq_psd(data_frame[key], np.mean(np.diff(data_frame[\"times\"])))\n",
    "    points_x=get_peak_points(freq, psd, height=0.003)\n",
    "    plt.plot(freq,psd - i * step, label=f\"channel {i+1} total acc\", zorder=1, lw=1)\n",
    "    #plt.scatter(points_x, - 1  * np.ones_like(points_x) * i * step)\n",
    "    if points_x is not None:\n",
    "            points_y=np.ones_like(points_x) * i * step * -1\n",
    "            print(f\"{key}: {str([np.round(i,1) for i in points_x])[1:-1]} Hz\")\n",
    "    else: \n",
    "        print(f\"{key} no peaks\")\n",
    "plt.legend(ncol=3, loc=9, edgecolor=\"white\")\n",
    "plt.grid(visible=True, axis=\"x\", ls=\"dashed\", alpha=0.4)\n",
    "plt.xticks(np.arange(0,110,5))\n",
    "plt.ylim(-1 * i * step - step/4, 1.5 * step)\n",
    "plt.xlabel(\"frequency [Hz]\")\n",
    "plt.ylabel(\"psd + offset\")\n",
    "plt.savefig(\"./total_psd_m1m3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801d153-2c87-46cb-8fd7-726d22b71d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frame=vms_m2_data\n",
    "step=0.005\n",
    "cols=[i for i in data_frame.columns if \"total\" in i]\n",
    "plt.figure(dpi=175, figsize=(10,4))\n",
    "plt.title(f\"M2\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\")\n",
    "for i, key in enumerate(cols):\n",
    "    freq,psd=get_freq_psd(data_frame[key], np.mean(np.diff(data_frame[\"times\"])))\n",
    "    points_x=get_peak_points(freq, psd, height=0.0005)\n",
    "    plt.plot(freq,psd - i * step, label=f\"channel {i+1} total acc\", zorder=1, lw=1)\n",
    "    #plt.scatter(points_x, - 1  * np.ones_like(points_x) * i * step)\n",
    "    if points_x is not None:\n",
    "            points_y=np.ones_like(points_x) * i * step * -1\n",
    "            print(f\"{key}: {str([np.round(i,1) for i in points_x if i > 0.1])[1:-1]} Hz\")\n",
    "    else: \n",
    "        print(f\"{key} no peaks\")\n",
    "plt.legend(ncol=3, loc=9, edgecolor=\"white\")\n",
    "plt.grid(visible=True, axis=\"x\", ls=\"dashed\", alpha=0.4)\n",
    "plt.xticks(np.arange(0,110,5))\n",
    "plt.ylim(-1 * i * step - step/4, 2 * step)\n",
    "plt.xlabel(\"frequency [Hz]\")\n",
    "plt.ylabel(\"psd + offset\")\n",
    "plt.savefig(\"./total_psd_m2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00616c60-c098-4086-ae50-9882bc9f206e",
   "metadata": {},
   "source": [
    "### log log for kevin\n",
    "We dont seem to have enough signal to do everything unless I extend the time to include some slews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85239e5c-ec0d-4ebf-a4a0-fe438b2a4865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "begin_time=Time('2023-06-28 00:13:30', format=\"iso\", scale=\"utc\")\n",
    "end_time=Time('2023-06-28 01:07:00', format=\"iso\", scale=\"utc\")\n",
    "efd_dict=get_efd_data(begin_time, end_time, eventMaker.client)\n",
    "vms_m1m3_data=get_vms_data(vms_m1m3_filename, begin_time.unix, end_time.unix, key_dict=key_m1m3_dict)\n",
    "vms_m2_data=get_vms_data(vms_m2_filename, begin_time.unix, end_time.unix, key_dict=key_m2_dict)\n",
    "# compute quadratic sum of accelerations in each channel\n",
    "for j in np.arange(3) +1:\n",
    "    vms_m1m3_data[f\"total_{j}\"] = np.linalg.norm(vms_m1m3_data[[f\"m1m3_{i}_{j}\" for i in [\"x\",\"y\",\"z\"]]].values, axis=1)\n",
    "\n",
    "for j in np.arange(6) + 1: \n",
    "    vms_m2_data[f\"total_{j}\"] = np.linalg.norm(vms_m2_data[[f\"m2_{i}_{j}\" for i in [\"x\",\"y\",\"z\"]]].values, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4baa8c-77fe-4b96-96cc-97c98fbd84bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(3, dpi=175, sharex=True, figsize=(10,5))\n",
    "plt.suptitle(f\"M1M3\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\\nForce Balance on, mirror raised, not slewing\", y=0.99)\n",
    "ax=axs[0]\n",
    "for i in np.arange(3):\n",
    "\n",
    "    axs[0].plot((Time(vms_m1m3_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m1m3_data[f\"m1m3_x_{i+1}\"]  - 0.002 * i,\n",
    "               label=f\"m1m3_x_{i+1}\")\n",
    "    axs[1].plot((Time(vms_m1m3_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m1m3_data[f\"m1m3_y_{i+1}\"] - 0.002 * i,\n",
    "               label=f\"m1m3_y_{i+1}\")\n",
    "    axs[2].plot((Time(vms_m1m3_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m1m3_data[f\"m1m3_z_{i+1}\"] - 0.002 * i,\n",
    "               label=f\"m1m3_z_{i+1}\"\n",
    "\n",
    "              )\n",
    "for i in np.arange(3):\n",
    "    axs[i].legend(ncol=3, edgecolor=\"white\", loc=9)\n",
    "    axs[i].set_ylabel(\"acceleration\\n[m/s^2]\")\n",
    "    axs[i].set_ylim(-0.005,0.003)\n",
    "axs[2].set_xlabel(\"Time [s]\")\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.savefig(f'./vms_look_m1m3_{end_time.iso.replace(\" \", \".\").replace(\":\",\"-\")[:-4]}.png', facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eeb6b8-7670-4b6a-99de-963e41429420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(3, dpi=175, sharex=True, figsize=(10,5))\n",
    "plt.suptitle(f\"M2\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\", y=0.99)\n",
    "ax=axs[0]\n",
    "for i in np.arange(6):\n",
    "\n",
    "    axs[0].plot((Time(vms_m2_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m2_data[f\"m2_x_{i+1}\"]  - 0.001 * i - np.mean(vms_m2_data[f\"m2_x_{i+1}\"]),\n",
    "               label=f\"m2_x_{i+1}\")\n",
    "    axs[1].plot((Time(vms_m2_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m2_data[f\"m2_y_{i+1}\"] - 0.001 * i - np.mean(vms_m2_data[f\"m2_y_{i+1}\"]),\n",
    "               label=f\"m2_y_{i+1}\")\n",
    "    axs[2].plot((Time(vms_m2_data[\"times\"], format=\"unix\")- begin_time).sec, \n",
    "               vms_m2_data[f\"m2_z_{i+1}\"] - 0.001 * i - np.mean(vms_m2_data[f\"m2_z_{i+1}\"]),\n",
    "               label=f\"m2_z_{i+1}\"\n",
    "\n",
    "              )\n",
    "for i in np.arange(3):\n",
    "    axs[i].legend(ncol=6, edgecolor=\"white\", loc=9)\n",
    "    axs[i].set_ylabel(\"acceleration\\n[m/s^2]\")\n",
    "    axs[i].set_ylim(-0.006,0.004)\n",
    "axs[2].set_xlabel(\"Time [s]\")\n",
    "plt.savefig(f'./vms_look_m2_{end_time.iso.replace(\" \", \".\").replace(\":\",\"-\")[:-4]}.png', facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fe7a4-d7fa-4df2-9043-af9af76426a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frame=vms_m1m3_data\n",
    "step=5\n",
    "cols=[i for i in data_frame.columns if \"total\" in i]\n",
    "plt.figure(dpi=175, figsize=(10,4))\n",
    "plt.title(f\"M1M3\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\")\n",
    "for i, key in enumerate(cols):\n",
    "    freq,psd=get_freq_psd(data_frame[key], np.mean(np.diff(data_frame[\"times\"])))\n",
    "    points_x=get_peak_points(freq, psd, height=0.3)\n",
    "    ydat=pd.DataFrame({\"psd\":psd})[\"psd\"].rolling(1).mean()\n",
    "    plt.plot(freq,ydat - i * step, label=f\"channel {i+1} total acc\", zorder=1, lw=0.5)\n",
    "    #plt.scatter(points_x,   np.ones_like(points_x))\n",
    "    if points_x is not None:\n",
    "            points_y=np.ones_like(points_x) * i * step * -1\n",
    "            print(f\"{key}: {str([np.round(i,1) for i in points_x if i >= 1])[1:-1]} Hz\")\n",
    "    else: \n",
    "        print(f\"{key} no peaks\")\n",
    "plt.legend(ncol=3, loc=9, edgecolor=\"white\")\n",
    "plt.savefig(\"total_psd_m1m3_long.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e0026-3d98-4296-8fa3-5585073bfca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frame=vms_m2_data\n",
    "step=2.5\n",
    "cols=[i for i in data_frame.columns if \"total\" in i]\n",
    "plt.figure(dpi=175, figsize=(10,4))\n",
    "plt.title(f\"M2\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\")\n",
    "for i, key in enumerate(cols):\n",
    "    freq,psd=get_freq_psd(data_frame[key], np.mean(np.diff(data_frame[\"times\"])))\n",
    "    points_x=get_peak_points(freq, psd, height=0.2)\n",
    "    ydat=pd.DataFrame({\"psd\":psd})[\"psd\"].rolling(1).mean()\n",
    "    plt.plot(freq,ydat + i * step, label=f\"channel {i+1} total acc\", zorder=1, lw=0.5)\n",
    "    #plt.scatter(points_x,   np.ones_like(points_x))\n",
    "    if points_x is not None:\n",
    "            points_y=np.ones_like(points_x) * i * step * -1\n",
    "            print(f\"{key}: {str([np.round(i,1) for i in points_x if i > 0.1])[1:-1]} Hz\")\n",
    "    else: \n",
    "        print(f\"{key} no peaks\")\n",
    "plt.legend(ncol=3, loc=9, edgecolor=\"white\")\n",
    "plt.ylim(-0.5,18)\n",
    "plt.savefig(\"total_psd_m2_long.png\", facecolor=\"white\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d5c29-df2b-4f0f-8209-ac267e5a3119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_frame=vms_m2_data\n",
    "step=0.000\n",
    "cols=[i for i in data_frame.columns if \"total\" in i]\n",
    "plt.figure(dpi=175, figsize=(10,4))\n",
    "plt.title(f\"M2\\n{begin_time.iso[:10]} {begin_time.iso[11:19]}-{end_time.iso[11:19]}\")\n",
    "for i, key in enumerate(cols):\n",
    "    freq,psd=get_freq_psd(data_frame[key], np.mean(np.diff(data_frame[\"times\"])))\n",
    "    points_x=get_peak_points(freq, psd, height=0.3)\n",
    "    ydat=pd.DataFrame({\"psd\":psd})[\"psd\"].rolling(200).mean()\n",
    "    plt.plot(freq,ydat, label=f\"channel {i+1} total acc\", zorder=1, lw=0.5)\n",
    "    #plt.scatter(points_x,   np.ones_like(points_x))\n",
    "    if points_x is not None:\n",
    "            points_y=np.ones_like(points_x) * i * step * -1\n",
    "            print(f\"{key}: {str([np.round(i,1) for i in points_x])[1:-1]} Hz\")\n",
    "    else: \n",
    "        print(f\"{key} no peaks\")\n",
    "plt.legend(ncol=3, loc=9, edgecolor=\"white\")\n",
    "#plt.ylim(-1 * i * step - 0.001, 0.005)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim(4e-4,1e1)\n",
    "plt.xlim(1e-1,1e2)\n",
    "plt.xlabel(\"frequency\")\n",
    "plt.ylabel(\"psd\")\n",
    "plt.savefig(\"./total_psd_log_m2.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
