{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Telescope EFD Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based off of `../MTMount_EFDAnalysis.ipynb` and more detail is in there\n",
    "\n",
    "This notebook seeks make histograms of MTMount velocity, acceleration, and jerk for long date ranges\n",
    "\n",
    "This notebook extracts data from the DM-EFD using [aioinflux](https://aioinflux.readthedocs.io/en/stable/index.html), a Python client for InfluxDB, and proceed with data analysis using Pandas dataframes. \n",
    "\n",
    "This is complementaty to the [Chronograf](https://test-chronograf-efd.lsst.codes) interface which we use for time-series visualization.\n",
    "\n",
    "In addition to `aioinflux`, you'll need to install `pandas`, `numpy` and `matplotlib` to run this notebook.\n",
    "\n",
    "This analysis will verify requirement 2.2.2 Slewing Rates in LTS-103 by comparing to accelerometer and encoder data. Plot distributiosn of each and superimpose the requirement spec. Need to explain/analyse ALL outliers as this is a glass safety issue. \n",
    "\n",
    "Go back into the historical data - check since begining of time.  ANALYSE  a night, and all data \n",
    "If no anomalies are found, we can set an upper limit and it must be monitored going forward. Passing this allows for acceptance of TMA from vendor but this must be continually monitored. \n",
    "\n",
    "If anomaliy - look for faults/messages from the MTMount CSC (Russel Owen). These can be found in the EFD - look at topics - like the encoder values \n",
    "\n",
    "ts-xml.lsst.io - describes the schema for the EFD and the values to extract. \n",
    "\n",
    "Ask Holger which test case this is associated with. \n",
    "\n",
    "This addresses \n",
    "5.  check slewing rates (velocity, acceleration, jerk) and motion profiles from all available previous historical telemetry. \n",
    "-- also need to cross check with DIMM data - mainly for jitter if we see accelleration problems. Can use DIMM to check and do a follow on data. DIMM data is in the LFA. This is a follow on post TMA acceptance. \n",
    "\n",
    "Main goal: Need to see accelerometer data coincide with encoder data.\n",
    "\n",
    "Ask qusestions on #rubinobs-sitcom-startracker\n",
    "\n",
    "2,3,6 have no effort \n",
    "2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pylab as plt\n",
    "import aioinflux\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from astropy.time import Time, TimeDelta\n",
    "\n",
    "from lsst_efd_client import EfdClient, resample\n",
    "from scipy.interpolate import interp1d\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change client if using USDF. \n",
    "client = EfdClient('usdf_efd')\n",
    "client.output = 'dataframe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll access the DM-EFD instance deployed at the summit. You need to be on site or connected to the NOAO VPN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare timestamps used for EFD queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Example date range\n",
    "t1 = Time('2023-02-01T02:35:01', scale='utc') \n",
    "# window = TimeDelta(90*24*60*60, format='sec')\n",
    "# t2=t1+window\n",
    "### Example \n",
    "#t1 = Time('2022-12-00T02:35:01', scale='utc') \n",
    "#window = TimeDelta(4, format='sec')\n",
    "#t2=t1+window\n",
    "t2 = Time('2023-03-17T02:35:01', scale='utc') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Date range for the formal verification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# time check verification\n",
    "print(t1.isot)\n",
    "print(t1.datetime64)\n",
    "print(t2.isot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load EFD data\n",
    "For this I have grabbed just the actualPosition and actualVelocity values for the alt and elevation encoders\n",
    "\n",
    "For a larger query (longer time range) may want to run query as a script and load results.\n",
    "\n",
    "See link for example query script in March 8th on #rubinobs-mtmount: https://lsstc.slack.com/archives/C047LHXRB4K/p1678251239301319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measured positions and velocities \n",
    "MTMount_Az = await client.select_time_series(\"lsst.sal.MTMount.azimuth\", \n",
    "                                                  [\"actualPosition\",\"actualVelocity\"], \n",
    "                                                  t1, t2)\n",
    "MTMount_El = await client.select_time_series(\"lsst.sal.MTMount.elevation\", [\"actualPosition\",\"actualVelocity\"] ,t1, t2)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTS-103 2.2.2 Slewing rate \n",
    "\n",
    "This section responds to requirements in LTS-103, 2.2.2 Slewing Rates\n",
    "\n",
    "2.2.2.1 Maximum Slewing Rate \n",
    "\n",
    "Specification: The slew and settling time requirements shall be met without exceeding the maximum\n",
    "limits, if these values are exceeded the telescope mount assembly shall be automatically stopped per\n",
    "the requirements of section 3.7.7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define relevant specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azimuth velocity min/max: ±10.5 deg/sec\n",
    "SPEC_AZ_VEL_MAX = 10.5\n",
    "\n",
    "# Azimuth acceleration: ±10.5 deg/s2\n",
    "SPEC_AZ_ACC_MAX = 10.5\n",
    "\n",
    "# Azimuth jerk: ±42.0 deg/s3\n",
    "SPEC_AZ_JERK_MAX = 42.0 \n",
    "\n",
    "# Elevation velocity: ±5.25 deg/s\n",
    "SPEC_ELEV_VEL_MAX = 5.25\n",
    "\n",
    "# Elevation acceleration: ±5.25 deg/s2\n",
    "SPEC_ELEV_ACC_MAX = 5.25\n",
    "\n",
    "# Elevation jerk: ±21.0 deg/s3\n",
    "SPEC_ELEV_JERK_MAX  = 21.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Acceleration/Jerk\n",
    "Combine into single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_frame_el = pd.DataFrame({\"time_el\":MTMount_El.index,\n",
    "                              \"relative_time_el\":(MTMount_El.index - MTMount_El.index[0]).total_seconds(),\n",
    "                              \"position_el\":MTMount_El[\"actualPosition\"].values,\n",
    "                              \"velocity_el\":MTMount_El[\"actualVelocity\"].values,\n",
    "                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is a matrix with n lines and 2 columns\n",
    "# def addInQuadrature(points):\n",
    "#     centroid = np.mean(points, axis=0)\n",
    "#     return np.sum(np.hypot(points[:,0]-centroid[0], points[:,1]-centroid[1]))\n",
    "\n",
    "# testPoints = np.\n",
    "# assert addInQuadrature(testPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az_pos_interp=interp1d(calculated_frame_el[\"relative_time_el\"], calculated_frame_el[\"position_el\"], bounds_error=False)\n",
    "\n",
    "\n",
    "calculated_frame_az = pd.DataFrame({\"time_az\":MTMount_Az.index,\n",
    "                              \"relative_time_az\":(MTMount_Az.index - MTMount_Az.index[0]).total_seconds(),\n",
    "                              \"position_az\":MTMount_Az[\"actualPosition\"].values,\n",
    "                              \n",
    "                              })\n",
    "calculated_frame_az[\"velocity_az\"]=MTMount_Az[\"actualVelocity\"].values * np.cos(np.radians(az_pos_interp(calculated_frame_az[\"relative_time_az\"])))\n",
    "\n",
    "calculated_frame_az[\"acceleration_az\"] = np.gradient(calculated_frame_az[\"velocity_az\"],\n",
    "                                                    calculated_frame_az[\"relative_time_az\"]) \n",
    "calculated_frame_az[\"jerk_az\"] = np.gradient(calculated_frame_az[\"acceleration_az\"],\n",
    "                                            calculated_frame_az[\"relative_time_az\"]) \n",
    "\n",
    "\n",
    "calculated_frame_el[\"acceleration_el\"] = np.gradient(calculated_frame_el[\"velocity_el\"],\n",
    "                                                    calculated_frame_el[\"relative_time_el\"]) \n",
    "calculated_frame_el[\"jerk_el\"] = np.gradient(calculated_frame_el[\"acceleration_el\"],\n",
    "                                            calculated_frame_el[\"relative_time_el\"]) \n",
    "\n",
    "\n",
    "calculated_frame_total = pd.DataFrame({\"time_total\":MTMount_Az.index,\n",
    "                              \"relative_time_total\":(MTMount_Az.index - MTMount_Az.index[0]).total_seconds(),\n",
    "                              \n",
    "                              })\n",
    "el_velocity_interp=interp1d(calculated_frame_el[\"relative_time_el\"], calculated_frame_el[\"velocity_el\"], bounds_error=False)\n",
    "calculated_frame_total[\"theta\"]=np.arctan(MTMount_Az[\"actualVelocity\"].values/el_velocity_interp(calculated_frame_total[\"relative_time_total\"].values))\n",
    "calculated_frame_total[\"velocity_total\"]=np.sqrt(calculated_frame_az[\"velocity_az\"].values**2 +\n",
    "                                                 el_velocity_interp(calculated_frame_total[\"relative_time_total\"].values)**2)\n",
    "calculated_frame_total[\"acceleration_total\"]=np.gradient(calculated_frame_total[\"velocity_total\"],\n",
    "                                            calculated_frame_total[\"relative_time_total\"]) \n",
    "calculated_frame_total[\"jerk_total\"] = np.gradient(calculated_frame_total[\"acceleration_total\"],\n",
    "                                            calculated_frame_total[\"relative_time_total\"]) \n",
    "\n",
    "calculated_frame=pd.concat([calculated_frame_az,calculated_frame_el, calculated_frame_total], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movement Histograms\n",
    "See sitcom 710: https://jira.lsstcorp.org/browse/SITCOM-710 \n",
    "\n",
    "- I think we just want full histograms for Alt, El, and (maybe total)\n",
    "- I also *think* for total speed (velocity) we need a cos(elevation) factor, but havent fully thought that through\n",
    "- I dont think position makes much sense here\n",
    "- I also dont know that the limits are but was planning on marking those for each hist with vertical lines\n",
    "- could remove the spike close to zero with a different sel_slew (2 cells below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for plotting \n",
    "mtypes=[\"az\",\"el\",\"total\"]\n",
    "color_dict={\"total\":\"k\",\n",
    "            \"az\":\"tab:red\",\n",
    "            \"el\":\"tab:blue\"}\n",
    "label_dict={\"total\":\"Total (speed)\",\n",
    "            \"az\": \"Azmiuth\",\n",
    "            \"el\": \"Elevation\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only times where the telescope is slewing\n",
    "sel_slew=(abs(calculated_frame[\"velocity_az\"]) > 0.04) | (abs(calculated_frame[\"velocity_el\"]) > 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sensible bin sizes to cover full range\n",
    "vel_list=[]\n",
    "acc_list=[]\n",
    "jerk_list=[]\n",
    "for i in mtypes:\n",
    "    vel_list.append(calculated_frame[f\"velocity_{i}\"])\n",
    "    acc_list.append(calculated_frame[f\"acceleration_{i}\"])\n",
    "    jerk_list.append(calculated_frame[f\"jerk_{i}\"])\n",
    "    \n",
    "\n",
    "\n",
    "vel_bins=np.arange(np.nanmin(vel_list),np.nanmax(vel_list),0.5)\n",
    "acc_bins=np.arange(np.nanmin(acc_list),np.nanmax(acc_list),0.1)\n",
    "jerk_bins=np.arange(np.nanmin(jerk_list),np.nanmax(jerk_list),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yMax=0\n",
    "\n",
    "fig,axs=plt.subplots(1,3,dpi=175, figsize=(13,5))\n",
    "plt.suptitle(f\"TMA movements\\n {t1.iso[:10]} : {t2.iso[:10]}\")\n",
    "for i in mtypes:\n",
    "    velHist=axs[0].hist(calculated_frame[f\"velocity_{i}\"][sel_slew], \n",
    "                bins=vel_bins, histtype=\"step\", color=color_dict[f\"{i}\"])\n",
    "    yMax=np.max([yMax,np.max(velHist[0])])\n",
    "\n",
    "\n",
    "axs[0].set_xlabel(\"Velocity [deg/s]\")\n",
    "\n",
    "for i in mtypes:\n",
    "    accHist=axs[1].hist(calculated_frame[f\"acceleration_{i}\"][sel_slew], \n",
    "                bins=acc_bins, histtype=\"step\", color=color_dict[i])\n",
    "    yMax=np.max([yMax,np.max(accHist[0])])\n",
    "        \n",
    "axs[1].set_xlabel(r\"Acceleration [deg/s$^2$]\")\n",
    "\n",
    "for i in mtypes:\n",
    "    jerkHist=axs[2].hist(calculated_frame[f\"jerk_{i}\"][sel_slew], \n",
    "                bins=jerk_bins, histtype=\"step\", color=color_dict[i], label=label_dict[i])\n",
    "    yMax=np.max([yMax,np.max(jerkHist[0])])\n",
    "        \n",
    "axs[2].set_xlabel(r\"Jerk [deg/s$^3$]\")\n",
    "axs[2].legend()\n",
    "\n",
    "#yMax=10e5\n",
    "for i in [0,1,2]:\n",
    "    ax=axs[i]\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(1e0,yMax * 1.2)\n",
    "    if i > 0:\n",
    "        ax.set_yticklabels([])\n",
    "    else:\n",
    "        ax.set_ylabel(\"count\")\n",
    "plt.subplots_adjust(wspace=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
